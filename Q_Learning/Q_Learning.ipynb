{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Basic Q learning implementation\n"
      ],
      "metadata": {
        "id": "B5IuzgfKksUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a=np.random.randn(3,3) # a.shape = (4, 3)a.shape=(4,3)\n",
        "\n",
        "b = np.random.randn(3, 3)\n",
        "\n",
        "c=a**2 + b.T**2\n",
        "\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPVF_74P_-I-",
        "outputId": "46dc6399-dcea-4a94-f2c2-86ebb04b7e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "q = np.matrix(np.zeros([6,6]))\n",
        "\n",
        "r = np.matrix([[-1, -1, -1, -1,  0,  -1],\n",
        "[-1, -1, -1,  0, -1, 100],\n",
        "[-1, -1, -1,  0, -1,  -1],\n",
        "[-1,  0,  0, -1,  0,  -1],\n",
        "[ 0, -1, -1,  0, -1, 100],\n",
        "[-1,  0, -1, -1,  0, 100]])\n",
        "\n",
        "gamma = 0.8\n",
        "epsilon = 0.4\n",
        "\n",
        "for episode in range(101):\n",
        "  state = np.random.randint(0,6)\n",
        "  while(state!=5):\n",
        "    possible_actions=[]\n",
        "    possible_q=[]\n",
        "    for action in range(6):\n",
        "      if r[state,action]>=0:\n",
        "        possible_actions.append(action)\n",
        "        possible_q.append(q[state,action])\n",
        "\n",
        "    action=-1\n",
        "    if np.random.random() < epsilon:\n",
        "      action = possible_actions[np.random.randint(0, len(possible_actions))]\n",
        "    else:\n",
        "      action = possible_actions[np.argmax(possible_q)]\n",
        "\n",
        "    q[state,action] = r[state, action] + gamma*q[action].max()\n",
        "\n",
        "    state = action\n",
        "\n",
        "  if episode%10==0:\n",
        "    print(\"Training episode: %d\" % episode)\n",
        "    print(q)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00aNOinmXMYa",
        "outputId": "c4a68270-9c2c-4d79-abd3-6d8ae8568a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training episode: 0\n",
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]]\n",
            "Training episode: 10\n",
            "[[  0.   0.   0.   0.  80.   0.]\n",
            " [  0.   0.   0.  64.   0. 100.]\n",
            " [  0.   0.   0.  64.   0.   0.]\n",
            " [  0.  80.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0. 100.]\n",
            " [  0.   0.   0.   0.   0.   0.]]\n",
            "Training episode: 20\n",
            "[[  0.   0.   0.   0.  80.   0.]\n",
            " [  0.   0.   0.  64.   0. 100.]\n",
            " [  0.   0.   0.  64.   0.   0.]\n",
            " [  0.  80.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0. 100.]\n",
            " [  0.   0.   0.   0.   0.   0.]]\n",
            "Training episode: 30\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.    0.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 40\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 50\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 60\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 70\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [ 64.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 80\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [ 64.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 90\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [ 64.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n",
            "Training episode: 100\n",
            "[[  0.    0.    0.    0.   80.    0. ]\n",
            " [  0.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.   64.    0.    0. ]\n",
            " [  0.   80.   51.2   0.   80.    0. ]\n",
            " [ 64.    0.    0.   64.    0.  100. ]\n",
            " [  0.    0.    0.    0.    0.    0. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cart pole using Q learning"
      ],
      "metadata": {
        "id": "iZfSO-FjkykY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "import math\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "print(env.action_space.n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kGpVrBdk0c6",
        "outputId": "6f6e0985-83d7-488c-c6c1-b5b9f197115a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE=0.1\n",
        "\n",
        "DISCOUNT=0.95\n",
        "EPISODES=100000\n",
        "total=0\n",
        "total_reward=0\n",
        "prior_reward=0\n",
        "\n",
        "Observation = [30,30,50,50]\n",
        "np_array_win_size= np.array([0.25,0.25,0.1,0.1])\n",
        "\n",
        "epsilon=0.6\n",
        "\n",
        "#epsilon_decay_value = 0.99995"
      ],
      "metadata": {
        "id": "nmIZ6yAklh6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.random.uniform(low=0, high=1, size=(Observation + [env.action_space.n]))\n",
        "q_table.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrYJNEoNnmvo",
        "outputId": "696761b2-c799-4112-c6e4-576e73e291e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 30, 50, 50, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discrete_state(state):\n",
        "  discrete_state = state/np_array_win_size+ np.array([15,10,1,10])\n",
        "  return tuple(discrete_state.astype(np.int))"
      ],
      "metadata": {
        "id": "anEk8LJCoD8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max=0\n",
        "for episode in range(EPISODES + 1):\n",
        "  t0 = time.time()\n",
        "  discrete_state=get_discrete_state(env.reset())\n",
        "  done=False\n",
        "  episode_reward=0\n",
        "  timet = 0\n",
        "  if episode %2000 ==0:\n",
        "    print(\"Episode: \" + str(episode))\n",
        "  while not done:\n",
        "    #env.render()\n",
        "    timet+=1\n",
        "    if np.random.random() > epsilon:\n",
        "      action = np.argmax(q_table[discrete_state])\n",
        "    else:\n",
        "      action = np.random.randint(0, env.action_space.n)\n",
        "\n",
        "    new_state, reward, done, _=env.step(action)\n",
        "\n",
        "    episode_reward += reward\n",
        "\n",
        "    new_discrete_state = get_discrete_state(new_state)\n",
        "\n",
        "    if not done:\n",
        "      max_future_q = np.max(q_table[new_discrete_state])\n",
        "\n",
        "      current_q = q_table[discrete_state + (action,)]\n",
        "\n",
        "      new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
        "\n",
        "      q_table[discrete_state + (action,)] = new_q\n",
        "\n",
        "    discrete_state = new_discrete_state\n",
        "\n",
        "  \"\"\"if epsilon>0.05:\n",
        "    if episode_reward > prior_reward and episode >10000:\n",
        "      epsilon = math.pow(epsilon_decay_value, episode - 10000)\n",
        "\n",
        "      if episode % 500 ==0:\n",
        "        print(\"Epsilon: \" + str(epsilon))\"\"\"\n",
        "\n",
        "  t1=time.time()\n",
        "  episode_total =t1-t0\n",
        "  total = total + episode_total\n",
        "\n",
        "  total_reward += episode_reward\n",
        "  prior_reward = episode_reward\n",
        "\n",
        "  if max < episode_reward:\n",
        "    max = episode_reward\n",
        "\n",
        "  if episode % 1000 == 0:\n",
        "    mean = total/1000\n",
        "    print(\"Time Average: \"+ str(mean))\n",
        "    total=0\n",
        "\n",
        "    print(\"Time = \"+ str(timet))\n",
        "\n",
        "    mean_reward = total_reward/1000\n",
        "    print(\"Mean Reward: \"+str(episode_reward))\n",
        "    total_reward = 0\n",
        "\n",
        "print(\"-------------------------\")\n",
        "print(max)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4Yi8kt9oznB",
        "outputId": "c808c8d7-400a-4e1d-d1d3-8f65da6759b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0\n",
            "Time Average: 2.9044151306152345e-06\n",
            "Time = 22\n",
            "Mean Reward: 22.0\n",
            "Time Average: 0.0012657699584960938\n",
            "Time = 34\n",
            "Mean Reward: 34.0\n",
            "Episode: 2000\n",
            "Time Average: 0.001738178014755249\n",
            "Time = 18\n",
            "Mean Reward: 18.0\n",
            "Time Average: 0.0021098966598510744\n",
            "Time = 32\n",
            "Mean Reward: 32.0\n",
            "Episode: 4000\n",
            "Time Average: 0.002218496084213257\n",
            "Time = 82\n",
            "Mean Reward: 82.0\n",
            "Time Average: 0.0024523165225982667\n",
            "Time = 49\n",
            "Mean Reward: 49.0\n",
            "Episode: 6000\n",
            "Time Average: 0.002152076482772827\n",
            "Time = 43\n",
            "Mean Reward: 43.0\n",
            "Time Average: 0.0021406819820404053\n",
            "Time = 23\n",
            "Mean Reward: 23.0\n",
            "Episode: 8000\n",
            "Time Average: 0.0020290515422821047\n",
            "Time = 51\n",
            "Mean Reward: 51.0\n",
            "Time Average: 0.0021178383827209473\n",
            "Time = 20\n",
            "Mean Reward: 20.0\n",
            "Episode: 10000\n",
            "Time Average: 0.002208613395690918\n",
            "Time = 56\n",
            "Mean Reward: 56.0\n",
            "Time Average: 0.002173272371292114\n",
            "Time = 21\n",
            "Mean Reward: 21.0\n",
            "Episode: 12000\n",
            "Time Average: 0.00220096755027771\n",
            "Time = 42\n",
            "Mean Reward: 42.0\n",
            "Time Average: 0.002359729051589966\n",
            "Time = 97\n",
            "Mean Reward: 97.0\n",
            "Episode: 14000\n",
            "Time Average: 0.002308102607727051\n",
            "Time = 100\n",
            "Mean Reward: 100.0\n",
            "Time Average: 0.002233431100845337\n",
            "Time = 83\n",
            "Mean Reward: 83.0\n",
            "Episode: 16000\n",
            "Time Average: 0.0023193566799163817\n",
            "Time = 80\n",
            "Mean Reward: 80.0\n",
            "Time Average: 0.002374821424484253\n",
            "Time = 93\n",
            "Mean Reward: 93.0\n",
            "Episode: 18000\n",
            "Time Average: 0.0023086495399475097\n",
            "Time = 14\n",
            "Mean Reward: 14.0\n",
            "Time Average: 0.002319301128387451\n",
            "Time = 25\n",
            "Mean Reward: 25.0\n",
            "Episode: 20000\n",
            "Time Average: 0.0022981388568878176\n",
            "Time = 81\n",
            "Mean Reward: 81.0\n",
            "Time Average: 0.002259550094604492\n",
            "Time = 22\n",
            "Mean Reward: 22.0\n",
            "Episode: 22000\n",
            "Time Average: 0.0023820140361785888\n",
            "Time = 88\n",
            "Mean Reward: 88.0\n",
            "Time Average: 0.002938054800033569\n",
            "Time = 103\n",
            "Mean Reward: 103.0\n",
            "Episode: 24000\n",
            "Time Average: 0.0024507153034210205\n",
            "Time = 47\n",
            "Mean Reward: 47.0\n",
            "Time Average: 0.0022818188667297363\n",
            "Time = 18\n",
            "Mean Reward: 18.0\n",
            "Episode: 26000\n",
            "Time Average: 0.0024199256896972657\n",
            "Time = 16\n",
            "Mean Reward: 16.0\n",
            "Time Average: 0.002324368476867676\n",
            "Time = 49\n",
            "Mean Reward: 49.0\n",
            "Episode: 28000\n",
            "Time Average: 0.0022357158660888674\n",
            "Time = 158\n",
            "Mean Reward: 158.0\n",
            "Time Average: 0.002455192804336548\n",
            "Time = 63\n",
            "Mean Reward: 63.0\n",
            "Episode: 30000\n",
            "Time Average: 0.002349129915237427\n",
            "Time = 50\n",
            "Mean Reward: 50.0\n",
            "Time Average: 0.0026129086017608644\n",
            "Time = 42\n",
            "Mean Reward: 42.0\n",
            "Episode: 32000\n",
            "Time Average: 0.002463650465011597\n",
            "Time = 43\n",
            "Mean Reward: 43.0\n",
            "Time Average: 0.0023241605758666994\n",
            "Time = 60\n",
            "Mean Reward: 60.0\n",
            "Episode: 34000\n",
            "Time Average: 0.0023847689628601074\n",
            "Time = 70\n",
            "Mean Reward: 70.0\n",
            "Time Average: 0.0023979196548461913\n",
            "Time = 42\n",
            "Mean Reward: 42.0\n",
            "Episode: 36000\n",
            "Time Average: 0.002436673879623413\n",
            "Time = 25\n",
            "Mean Reward: 25.0\n",
            "Time Average: 0.0024618258476257326\n",
            "Time = 18\n",
            "Mean Reward: 18.0\n",
            "Episode: 38000\n",
            "Time Average: 0.002395735502243042\n",
            "Time = 15\n",
            "Mean Reward: 15.0\n",
            "Time Average: 0.0024566662311553953\n",
            "Time = 28\n",
            "Mean Reward: 28.0\n",
            "Episode: 40000\n",
            "Time Average: 0.00241766095161438\n",
            "Time = 109\n",
            "Mean Reward: 109.0\n",
            "Time Average: 0.0023919286727905275\n",
            "Time = 16\n",
            "Mean Reward: 16.0\n",
            "Episode: 42000\n",
            "Time Average: 0.0024821727275848387\n",
            "Time = 94\n",
            "Mean Reward: 94.0\n",
            "Time Average: 0.00251601243019104\n",
            "Time = 21\n",
            "Mean Reward: 21.0\n",
            "Episode: 44000\n",
            "Time Average: 0.002509242057800293\n",
            "Time = 61\n",
            "Mean Reward: 61.0\n",
            "Time Average: 0.002507674932479858\n",
            "Time = 59\n",
            "Mean Reward: 59.0\n",
            "Episode: 46000\n",
            "Time Average: 0.0024655466079711915\n",
            "Time = 23\n",
            "Mean Reward: 23.0\n",
            "Time Average: 0.0024635124206542967\n",
            "Time = 41\n",
            "Mean Reward: 41.0\n",
            "Episode: 48000\n",
            "Time Average: 0.0024395179748535156\n",
            "Time = 114\n",
            "Mean Reward: 114.0\n",
            "Time Average: 0.002450310230255127\n",
            "Time = 63\n",
            "Mean Reward: 63.0\n",
            "Episode: 50000\n",
            "Time Average: 0.002536066770553589\n",
            "Time = 15\n",
            "Mean Reward: 15.0\n",
            "Time Average: 0.0025765273571014403\n",
            "Time = 98\n",
            "Mean Reward: 98.0\n",
            "Episode: 52000\n",
            "Time Average: 0.0024426536560058594\n",
            "Time = 34\n",
            "Mean Reward: 34.0\n",
            "Time Average: 0.0024835290908813475\n",
            "Time = 105\n",
            "Mean Reward: 105.0\n",
            "Episode: 54000\n",
            "Time Average: 0.002676647424697876\n",
            "Time = 49\n",
            "Mean Reward: 49.0\n",
            "Time Average: 0.0024574058055877685\n",
            "Time = 10\n",
            "Mean Reward: 10.0\n",
            "Episode: 56000\n",
            "Time Average: 0.002626021146774292\n",
            "Time = 43\n",
            "Mean Reward: 43.0\n",
            "Time Average: 0.0024609522819519043\n",
            "Time = 61\n",
            "Mean Reward: 61.0\n",
            "Episode: 58000\n",
            "Time Average: 0.0024504899978637696\n",
            "Time = 40\n",
            "Mean Reward: 40.0\n",
            "Time Average: 0.0025851831436157226\n",
            "Time = 70\n",
            "Mean Reward: 70.0\n",
            "Episode: 60000\n",
            "Time Average: 0.0024830825328826904\n",
            "Time = 95\n",
            "Mean Reward: 95.0\n",
            "Time Average: 0.0025199637413024904\n",
            "Time = 43\n",
            "Mean Reward: 43.0\n",
            "Episode: 62000\n",
            "Time Average: 0.0026096251010894775\n",
            "Time = 132\n",
            "Mean Reward: 132.0\n",
            "Time Average: 0.00255997109413147\n",
            "Time = 21\n",
            "Mean Reward: 21.0\n",
            "Episode: 64000\n",
            "Time Average: 0.002640378713607788\n",
            "Time = 72\n",
            "Mean Reward: 72.0\n",
            "Time Average: 0.002705961227416992\n",
            "Time = 14\n",
            "Mean Reward: 14.0\n",
            "Episode: 66000\n",
            "Time Average: 0.002498286008834839\n",
            "Time = 68\n",
            "Mean Reward: 68.0\n",
            "Time Average: 0.0024842164516448973\n",
            "Time = 51\n",
            "Mean Reward: 51.0\n",
            "Episode: 68000\n",
            "Time Average: 0.002643458843231201\n",
            "Time = 100\n",
            "Mean Reward: 100.0\n",
            "Time Average: 0.002664815902709961\n",
            "Time = 92\n",
            "Mean Reward: 92.0\n",
            "Episode: 70000\n",
            "Time Average: 0.0026623587608337403\n",
            "Time = 18\n",
            "Mean Reward: 18.0\n",
            "Time Average: 0.0025864789485931395\n",
            "Time = 81\n",
            "Mean Reward: 81.0\n",
            "Episode: 72000\n",
            "Time Average: 0.0025964038372039795\n",
            "Time = 16\n",
            "Mean Reward: 16.0\n",
            "Time Average: 0.002493400812149048\n",
            "Time = 32\n",
            "Mean Reward: 32.0\n",
            "Episode: 74000\n",
            "Time Average: 0.002560462474822998\n",
            "Time = 30\n",
            "Mean Reward: 30.0\n",
            "Time Average: 0.0025888330936431883\n",
            "Time = 45\n",
            "Mean Reward: 45.0\n",
            "Episode: 76000\n",
            "Time Average: 0.0026676161289215087\n",
            "Time = 28\n",
            "Mean Reward: 28.0\n",
            "Time Average: 0.002461725950241089\n",
            "Time = 22\n",
            "Mean Reward: 22.0\n",
            "Episode: 78000\n",
            "Time Average: 0.002612599849700928\n",
            "Time = 25\n",
            "Mean Reward: 25.0\n",
            "Time Average: 0.002603224754333496\n",
            "Time = 87\n",
            "Mean Reward: 87.0\n",
            "Episode: 80000\n",
            "Time Average: 0.0028595798015594483\n",
            "Time = 66\n",
            "Mean Reward: 66.0\n",
            "Time Average: 0.0029101788997650145\n",
            "Time = 88\n",
            "Mean Reward: 88.0\n",
            "Episode: 82000\n",
            "Time Average: 0.002635471343994141\n",
            "Time = 147\n",
            "Mean Reward: 147.0\n",
            "Time Average: 0.0025296370983123777\n",
            "Time = 148\n",
            "Mean Reward: 148.0\n",
            "Episode: 84000\n",
            "Time Average: 0.00268681263923645\n",
            "Time = 168\n",
            "Mean Reward: 168.0\n",
            "Time Average: 0.0024663279056549073\n",
            "Time = 31\n",
            "Mean Reward: 31.0\n",
            "Episode: 86000\n",
            "Time Average: 0.0026112818717956543\n",
            "Time = 126\n",
            "Mean Reward: 126.0\n",
            "Time Average: 0.0026505911350250245\n",
            "Time = 30\n",
            "Mean Reward: 30.0\n",
            "Episode: 88000\n",
            "Time Average: 0.0024321005344390867\n",
            "Time = 106\n",
            "Mean Reward: 106.0\n",
            "Time Average: 0.0024992456436157225\n",
            "Time = 31\n",
            "Mean Reward: 31.0\n",
            "Episode: 90000\n",
            "Time Average: 0.00257711124420166\n",
            "Time = 75\n",
            "Mean Reward: 75.0\n",
            "Time Average: 0.0027155847549438475\n",
            "Time = 71\n",
            "Mean Reward: 71.0\n",
            "Episode: 92000\n",
            "Time Average: 0.0025594625473022463\n",
            "Time = 127\n",
            "Mean Reward: 127.0\n",
            "Time Average: 0.0026958816051483154\n",
            "Time = 80\n",
            "Mean Reward: 80.0\n",
            "Episode: 94000\n",
            "Time Average: 0.0025662424564361574\n",
            "Time = 77\n",
            "Mean Reward: 77.0\n",
            "Time Average: 0.002591449975967407\n",
            "Time = 149\n",
            "Mean Reward: 149.0\n",
            "Episode: 96000\n",
            "Time Average: 0.002544968128204346\n",
            "Time = 43\n",
            "Mean Reward: 43.0\n",
            "Time Average: 0.002620006799697876\n",
            "Time = 18\n",
            "Mean Reward: 18.0\n",
            "Episode: 98000\n",
            "Time Average: 0.0024590070247650147\n",
            "Time = 16\n",
            "Mean Reward: 16.0\n",
            "Time Average: 0.0025449416637420654\n",
            "Time = 18\n",
            "Mean Reward: 18.0\n",
            "Episode: 100000\n",
            "Time Average: 0.0026291196346282957\n",
            "Time = 92\n",
            "Mean Reward: 92.0\n",
            "-------------------------\n",
            "389.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mountain Car using Q learning"
      ],
      "metadata": {
        "id": "wFuL1hrJCtRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "env.reset()\n",
        "\n",
        "learning=0.2\n",
        "discount = 0.9\n",
        "epsilon = 0.8\n",
        "min_eps = 0\n",
        "episodes = 5000\n",
        "\n",
        "\n",
        "num_states = (env.observation_space.high - env.observation_space.low)*\\\n",
        "                    np.array([10, 100])\n",
        "num_states = np.round(num_states, 0).astype(int)+1\n",
        "\n",
        "\n",
        "Q = np.random.uniform(low=-1, high=1, size = (num_states[0], num_states[1], env.action_space.n))\n",
        "\n",
        "reward_list=[]\n",
        "ave_reward_list=[]\n",
        "\n",
        "reduction = (epsilon-min_eps)/episodes\n",
        "\n",
        "for i in range(episodes):\n",
        "  done=False\n",
        "  tot_reward, reward = 0,0\n",
        "  state=env.reset()\n",
        "\n",
        "  state_adj = (state - env.observation_space.low)*np.array([10, 100])\n",
        "  state_adj = np.round(state_adj, 0).astype(int)\n",
        "\n",
        "  while not done:\n",
        "    env.render()\n",
        "\n",
        "    if np.random.random() < 1-epsilon:\n",
        "      action = np.argmax(Q[state_adj[0], state_adj[1]])\n",
        "    else:\n",
        "      action = np.random.randint(0, env.action_space.n)\n",
        "\n",
        "    state2, reward, done, info = env.step(action)\n",
        "\n",
        "    state2_adj = (state2 - env.observation_space.low)*np.array([10, 100])\n",
        "    state2_adj = np.round(state2_adj, 0).astype(int)\n",
        "\n",
        "    if done and state2[0] >= 0.5:\n",
        "      Q[state_adj[0], state_adj[1], action] = reward\n",
        "\n",
        "    else:\n",
        "      delta = learning*(reward + discount*np.max(Q[state2_adj[0], state2_adj[1]]) - Q[state_adj[0], state_adj[1], action])\n",
        "      Q[state_adj[0], state_adj[1], action] += delta\n",
        "\n",
        "    tot_reward +=reward\n",
        "    state_adj = state2_adj\n",
        "\n",
        "  if epsilon > min_eps:\n",
        "    epsilon -= reduction\n",
        "\n",
        "  reward_list.append(tot_reward)\n",
        "\n",
        "  if (i+1) % 100 ==0:\n",
        "    ave_reward = np.mean(reward_list)\n",
        "    ave_reward_list.append(ave_reward)\n",
        "    reward_list = []\n",
        "\n",
        "  if (i+1) % 100 ==0:\n",
        "    print('Episode {} Average Reward: {}'.format(i+1, ave_reward))\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n",
        "plt.plot(100*(np.arange(len(ave_reward_list)) + 1), ave_reward_list)\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Average Reward')\n",
        "plt.title('Average Reward vs Episodes')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v4j6jCj2CwcE",
        "outputId": "9193b988-c861-40d4-eb16-65601556cadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100 Average Reward: -200.0\n",
            "Episode 200 Average Reward: -200.0\n",
            "Episode 300 Average Reward: -200.0\n",
            "Episode 400 Average Reward: -200.0\n",
            "Episode 500 Average Reward: -200.0\n",
            "Episode 600 Average Reward: -200.0\n",
            "Episode 700 Average Reward: -200.0\n",
            "Episode 800 Average Reward: -200.0\n",
            "Episode 900 Average Reward: -200.0\n",
            "Episode 1000 Average Reward: -200.0\n",
            "Episode 1100 Average Reward: -200.0\n",
            "Episode 1200 Average Reward: -200.0\n",
            "Episode 1300 Average Reward: -200.0\n",
            "Episode 1400 Average Reward: -200.0\n",
            "Episode 1500 Average Reward: -200.0\n",
            "Episode 1600 Average Reward: -200.0\n",
            "Episode 1700 Average Reward: -200.0\n",
            "Episode 1800 Average Reward: -200.0\n",
            "Episode 1900 Average Reward: -200.0\n",
            "Episode 2000 Average Reward: -200.0\n",
            "Episode 2100 Average Reward: -200.0\n",
            "Episode 2200 Average Reward: -200.0\n",
            "Episode 2300 Average Reward: -200.0\n",
            "Episode 2400 Average Reward: -200.0\n",
            "Episode 2500 Average Reward: -200.0\n",
            "Episode 2600 Average Reward: -200.0\n",
            "Episode 2700 Average Reward: -200.0\n",
            "Episode 2800 Average Reward: -199.29\n",
            "Episode 2900 Average Reward: -200.0\n",
            "Episode 3000 Average Reward: -200.0\n",
            "Episode 3100 Average Reward: -200.0\n",
            "Episode 3200 Average Reward: -199.78\n",
            "Episode 3300 Average Reward: -199.62\n",
            "Episode 3400 Average Reward: -198.63\n",
            "Episode 3500 Average Reward: -198.59\n",
            "Episode 3600 Average Reward: -199.36\n",
            "Episode 3700 Average Reward: -198.67\n",
            "Episode 3800 Average Reward: -199.92\n",
            "Episode 3900 Average Reward: -199.31\n",
            "Episode 4000 Average Reward: -198.93\n",
            "Episode 4100 Average Reward: -198.28\n",
            "Episode 4200 Average Reward: -197.53\n",
            "Episode 4300 Average Reward: -199.69\n",
            "Episode 4400 Average Reward: -199.9\n",
            "Episode 4500 Average Reward: -192.58\n",
            "Episode 4600 Average Reward: -184.08\n",
            "Episode 4700 Average Reward: -191.29\n",
            "Episode 4800 Average Reward: -191.33\n",
            "Episode 4900 Average Reward: -196.15\n",
            "Episode 5000 Average Reward: -198.19\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXycZb338c83e9I2SUs36E5bllqg0FBAUZCCoCIIglARVFRE5FERj4ogwjkeH4+i4goUBfGRVY4FhCObbHpYU2hLF6gttHSjG83SNm223/PHfU0ZwiS508ySSX/v12teueder2uazi/XLjPDOeeci6Mg1wlwzjmXPzxoOOeci82DhnPOudg8aDjnnIvNg4ZzzrnYPGg455yLzYOGc32cJJM0KdfpSEXS+yW9moH79tk87+k8aLgekfSEpC2SSnOdlt6SdJWkFklbJdVJelrSUblOV7ZJ+qyktvA5JL/26e5aM/uHme2fjXS6vsGDhotN0njg/YABp2Tg/kXpvmcMd5rZQGAo8Djw5xykAchZ/hOeMbOBHV5rc5ge10d50HA9cR7wLPAH4DMAkkrDX+lTEydJGiapSdLw8P5kSfOS/po/OOncFZK+LWkBsE1SkaTvSFouqVHSYkmnJZ1fKOmnkjZJel3SxaEqoygcr5L0e0nrJK2R9ANJhd1lzMxagVuBUZKGdXcvSSslTQ/b54Q0vCe8/7yke8L2DEnPhLyvk/RrSSVJ+TFJX5H0L+BfYd+/hXPXSjq/szRLOktSbYd9l0i6L2x/JHx+jSH93+zuc+jkOSskXRbutUXSzZLKwrFjJa1OOvfb4VmNkl6VNDPsL5V0bcjT2rBdmnRdp3kO114j6Q1J6yVdL6k8HBsq6f7w+b4l6R+S/Hstg/zDdT1xHtEX663AiZJGmNlO4C/ArKTzPgk8aWYbJB0K3AR8CdgLuAG4r0P11izgo0B1+PJeTlSiqQKuBv4kae9w7heBDwPTgMOAj3dI4x+AVmAScCjwIeAL3WUsfJGfB2wGtsS415PAsWH7GOA14ANJ758M223AJUQlmaOAmcBFHR7/ceAIYIqkk4BvAicAk4Hju0j2X4H9JU1O2vcp4Law/XvgS2Y2CJgKPNbFvbpzDnAiMBHYD7ii4wmS9gcuBg4PzzwRWBEOXw4cSfTvdggwI3GPGHn+UXjmNKJ/i1HAleHYpcBqYBgwAvguUUnYZYqZ+ctf3b6Ao4EWYGh4/wpwSdg+HliedO7/AueF7euA/+hwr1eBY8L2CuD8bp49Dzg1bD9G9EVI0rMNKCL60tgJlCcdnwU83sl9rwKagTqiL/fNwLHhWJf3Aj4P3Be2lxAFkzvC+5XAYZ088+vAnKT3BhyX9P4m4EdJ7/cL50zq5H5/Aq4M25OBRqAivH+DKFhXdvP5fpYoONYlvZL/PVcAFya9/0jiOFHgXB22JwEbwr9JcYdnLAc+kvT+RGBFd3kGBGwDJiYdPwp4PWz/O3BvZ5+Pv9L/8pKGi+szwMNmtim8vy3sg6gtoELSEaHdYxowJxwbB1waqg/qJNUBY4DkRtZVyQ+SdF5SdVYd0V/JQ8PhfTqcn7w9DigG1iVdewMwvIt83WVm1URBYiEwPea9ngTeH0pAhcBdwPtC/quIAh2S9gvVJ29KagB+mJSXVHnomL+VXaQdon+HRCnvU8A9ZrY9vP8E0Rf8SklPqutG/mfNrDrpNbGLNK7knf9+AJjZMqKgeBWwQdIdersxfZ8OeUm+R1d5HgZUAHOT/h0eDPsBfgIsAx6W9Jqk73SRR5cGuWx4c3ki1B9/EiiU9GbYXQpUSzrEzOZLuovoy2s9cL+ZNYbzVgH/aWb/2cUjdlUnSBoH3EhUjfOMmbVJmkf0FyfAOmB00rVjkrZXEZUOhlpUzRWbmW2SdAFQK+m27u5lZsskbQf+D/CUmTWEz+YC4J9m1h5OvQ54CZhlZo2Svg6c0Vn+Q/6S8zS2m6Q/AgyTNI3o878kKY0vAKdKKiaqNrqrw717omOaUjaSm9ltwG2SKomC7H8B54bzxwGLUtyjqzxvApqA95jZmhTPaySqorpUUbvaY5JeMLO/9yx7Li4vabg4Pk5UfTOFqBQxDTgQ+AdROwBEf/GeRVT3fVvStTcCF4ZSiCQNkPRRSYM6edYAoi/RjQCSPkdU0ki4C/iapFGSqoFvJw6Y2TrgYeCnkiolFUiaKOmYOJk0s1eBh4BvxbzXk0Rfxon2iyc6vAcYBDQAWyUdAHy5m2TcBXxW0hRJFcD3u0lzC1GPr58AQ4iCCJJKFDXQV4VzGoD2zu/Ura9IGi1pCFH7xJ0dT5C0v6TjQnvVDqIv+8QzbweuUNRJYihRm8SfustzCL43Aj/X2x0rRkk6MWyfLGmSJAH1RL+nvcmn64YHDRfHZ4CbzewNM3sz8QJ+DZwjqcjMniOqe94H+FviQjOrJWq8/jVRA/Myojr0lMxsMfBT4BmiUstBRG0kCTcSfZkvIPoL/n+I6uPbwvHzgBJgcXje3cDexPcT4ILwBdXdvZ4kCgpPdfIeogbeTxG1NdxIii/bZGb2N+BaorabZcRrvL6NqB3hzx1KRecCK0K12IVEAb0zR+nd4zQO7/CMh4ka/JcDP0hxj1KiRutNwJtEVXmXhWM/AGqJ/t1eBl5M3CNGnr8d9j8b8vIokBgbMjm830r0O/NbM3u8i3y6XpKZdzRw+UvSh4HrzWxcrtPSX0laAXzBzB7NdVpc7nlJw+UVSeWKxh8USRpFVJUxp7vrnHPp4UHD5RsRjd3YQlQ9tYS3++w75zLMq6ecc87F5iUN55xzsfX7cRpDhw618ePH5zoZzjmXV+bOnbvJzIZ13N/vg8b48eOpra3t/kTnnHO7SEo5G4FXTznnnIvNg4ZzzrnYPGg455yLzYOGc8652HIWNCSdKWmRpHZJNUn7iyXdIullSUskXdbhukJJL0m6P/upds65PVsuSxoLgdN55+RuAGcCpWZ2ENHaBl8KaxQkfI1oFLBzzrksy1nQMLMlYSrqdx0CBiha87mcaGW1BgBJo4mWBf1d1hLqnHNul77YpnE30RTb64iWq7zGzN4Kx64FvkU38+VLukBSraTajRs3ZjSxzjnXEzta2rirdhX5OoVTRoOGpEclLUzxOrWLy2YQrY2wDzCBaEWufSWdDGwws7ndPdfMZptZjZnVDBv2rgGNzjmXM4+/soFv3b2ARWsbcp2U3ZLREeFmdvxuXPYp4MGw2tgGSf8L1ACHAqdI+ghQBlRK+pOZfTp9KXbOucyqa2oB4K1tzTlOye7pi9VTbwDHAUgaABwJvGJml5nZaDMbD5wNPOYBwzmXbxp3REEjETzyTS673J4maTVwFPCApIfCod8AAyUtAl4gWmZ0Qa7S6Zxz6dS4I1qRtz5Pg0bOJiw0szmkWHHNzLYSdbvt6tongCcykjDnnMugXUFju1dPOeec60ZDonpqe36WNDxoOOdcFiVKGt6m4ZxzrluJhvB8bdPwoOGcc1n0dpuGBw3nnHPdeLt6yhvCnXPOdaPRG8Kdc87FYWbeEO6ccy6eHS3ttLYblWVFNLe2s6OlLddJ6jEPGs45lyWJqqkxQyqA/Kyi8qDhnHNZ0hCqpsYMDkEjDxvDPWg451yWJEoaoweXA17ScM4514VdJY1QPZWPA/w8aDjnXJa83aYRlTTycYCfBw3nnMuSRm/TcM45F1eipDGyqozCAnmbhnPOuc417milQDCwtIjq8mJv04hL0pmSFklql1STtL9Y0i2SXpa0RNJlSceqJd0t6ZVw7KhcpN0553ZX445WBpYWIYmqiuK8HBWeq5LGQuB04KkO+88ESs3sIGA68CVJ48OxXwAPmtkBwCHAkuwk1Tnn0qNhRwuDyooBopJGHlZP5WS5VzNbAiDpXYeAAZKKgHKgGWiQVAV8APhsuL45HHPOubzRuKOVQWXR125VeTEbt+7McYp6rq+1adwNbAPWAW8A15jZW8AEYCNws6SXJP1O0oDObiLpAkm1kmo3btyYlYQ751x3Gne0UJkoaVSUeJtGMkmPSlqY4nVqF5fNANqAfYgCxaWS9iUqER0GXGdmhxIFlu90dhMzm21mNWZWM2zYsPRlyjnneqFjSSMfe09lrHrKzI7fjcs+RdRu0QJskPS/QA1R28dqM3sunHc3XQQN55zrixp3tDJ5ePS1W11RTOOOVlrb2ikq7GuVPp3rayl9AzgOIFQ/HQm8YmZvAqsk7R/Omwkszk0SnXNu9zQmNYRXlUc/E1OL5Itcdbk9TdJq4CjgAUkPhUO/AQZKWgS8ANxsZgvCsf8D3CppATAN+GG20+2cc7srsQBTonqquiIKGnXb86tPT656T80B5qTYv5Wo222qa+YRVVU551zeSSzA9HaX2xIg/yYt7GvVU8451y8lphDZ1RCeKGl40HDOOddRQ8egEdo08m2AnwcN55zLgkSDd2XSiHDIvzYNDxrOOZcFiWnR31XSaPLeU8455zp4u00jChZFhQUMKi3KuzU1PGg451wWJEoaleVvd1qtzMNJCz1oOOdcFnQsaUA0VsN7TznnnHuXxAJMA0oKd+2rrsi/hZg8aDjnXBYkL8CUUF1e4r2nnHPOvVvyAkwJVV7ScM45l0ryvFMJienRzSxHqeo5DxrOOZcFyQswJVSXF9PabmxvbstRqnrOg4ZzzmVBqpJGdR7OP+VBwznnsiB19VQ0020+NYZ70HDOuSxoTNUQnoeTFnrQcM65DOu4AFOCV0/1gKQzJS2S1C6pJml/saRbJL0saYmky5KOXRKuWSjpdklluUm9c87F19TS9o4FmBISQSOfut3msqSxEDgdeKrD/jOBUjM7CJgOfEnSeEmjgK8CNWY2FSgEzs5mgp1zbnd0nOE2oXpXm0b+BI2cLPcKYGZLgHeMjkwcAgZIKgLKgWagIWwXAeWSWoAKYG3WEuycc7up46p9CWXFBZQUFuTVTLd9sU3jbmAbsA54A7jGzN4yszXANWHfOqDezB5OdQNJF0iqlVS7cePGbKXbOedS6rgAU4KkaFR4HpU0Mho0JD0a2h86vk7t4rIZQBuwDzABuFTSvpIGA6eGffsQlUY+neoGZjbbzGrMrGbYsGFpzpVzzvVMqmnRE6rL82sqkYxWT5nZ8btx2aeAB82sBdgg6X+BGqJqq9fNbCOApL8A7wX+lK70OudcJqSaFj2huqI4r9o0+mL11BvAcQCSBgBHAq+E/UdKqlDUEDITWJKzVDrnXEydNYRDmH8qj0oauexye5qk1cBRwAOSHgqHfgMMlLQIeAG42cwWmNlzRO0dLwIvE6V9dg6S7pxzPdJVSaOqvIT6PBoRnsveU3OAOSn2byXqdpvqmu8D389w0pxzLq1SLcCUkG8LMfXF6innnOtXUi3AlFBdXsy25jaaW9tzkLKe86DhnHMZlmoBpoSqPBsV7kHDOecyLNW8Uwm7Ji3MkwF+HjSccy7DUi3AlFBdkV9TiXjQcM65DOuqpFFd7tVTzjnnknQZNBLTo+dJSaPTLreSTu/qQjP7S/qT45xz/U+qBZgSEm0a+TLAr6txGh8LP4cTTdfxWHj/QeBpwIOGc851w8xo6KKkMaisGIm8GeDXadAws88BSHoYmGJm68L7vYE/ZCV1zjmX55pa2mhLsQBTQmGBqCzLnwF+cdo0xiQCRrAeGJuh9DjnXL/S1bxTCdUV+TP/VJxpRP4e5oW6Pbw/C3g0c0lyzrn+o7MFmJJVlefPTLfdBg0zu1jSacAHwq7ZYd4o55xz3di1AFN56uopyK+ZbrsMGpIKgUVmdgApJhd0zjnXtV0LMHVZPVXC6i1N2UpSr3TZpmFmbcCrkrwNwznndkNX06InVJcXU5fvvaeSDAYWSXqeaO1uAMzslIylyjnn+ok4DeFVYcnX9najoODdM+H2JXGCxvcyngrnnOunYpU0KoppN2jc2bprsF9f1W2XWzN7MtWrNw+VdKakRZLaJdUk7S+RdLOklyXNl3Rs0rHpYf8ySb9UqonpnXOuj+lqAaaERKBoyIPG8G6DhqQjJb0gaaukZkltkhp6+dyFwOnAUx32fxHAzA4CTgB+KimRxuvC8cnhdVIv0+CccxnX1QJMCfk0022cwX2/BmYB/wLKgS8QreO928xsiZm9muLQFMJ0JWa2AagDasIo9Eoze9bMDPgj8PHepME557KhqwWYEt6ef6rvN4bHmuXWzJYBhWbWZmY3k7m/8ucDp0gqkjQBmA6MAUYBq5POWx32pSTpAkm1kmo3btyYoaQ651z3uprhNiGfZrqN0xC+XVIJME/Sj4F1xKvWehQYmeLQ5WZ2byeX3QQcCNQCK4kmRmyLkcZ3MLPZwGyAmpoa6+n1zjmXLl0twJRQnUcz3cYJGucSBYmLgUuI/vL/RHcXmdnxPU2MmbWGZwAg6WlgKbAFGJ106mhgTU/v75xz2da4o5WRlWVdnlOZRw3hcYLGJGCDmTUAV2cyMZIqAJnZNkknAK1mtjgca5B0JPAccB7wq0ymxTnn0qFhRwuThw/s8pyy4kLKiwvzYoBfnKBxHnCdpLeAfxD1ePqnmW3Z3YeGuax+BQwDHpA0z8xOJFq74yFJ7UQliXOTLruIaEr2cuBv4eWcc31a1KbR/diLfJm0MM6EhZ8BkLQPcAZRz6l94lzbxT3nkGIuKzNbAezfyTW1wNTdfaZzzmWbmcVqCIf8mR6925xI+jTwfuAgYBNRF9x/ZDhdzjmX97pbgClZYiqRvi5OaeFaYDlwPfB4KA0455zrRpx5pxKqK4pZsWl7ppPUa3GmERkKnA+UAf8p6XlJ/y/jKXPOuTyXmHeqq7U0EqI1Nfp+Q3ic8RaVRMu7jgPGA1VAe2aT5Zxz+a+hRyWNkv7REA78M+n1azNb3c35zjnniLcAU0JVeTE7W9vZ0dJGWXHnkxvmWpzeUwdDNIbCzPp+hZtzzvURcaZFT0hMJVLf1NKng0ac6qmjJC0GXgnvD5H024ynzDnn8lxPGsJ3TVrYx6uo4kxYeC1wIrAZwMzmAx/IZKKcc64/6FFJozwxPXrfbgyPO8vtqg67ejyJoHPO7WniLMCUkFw91ZfFaQhfJem9gEkqBr4GLMlsspxzLv/FWYApIRE0Lr1rPsMrX2HIgJJ3vE47dDSTupnDKhviBI0LgV8QrV+xBniYaB4o55xzXYizAFPCqOpyrjx5Cq9t2spb25p5a1szr2/axtyVdWzetpN1dTv42VnTMpzi7sXpPbUJOCfxXtJgoqDxnxlMl3PO5b24804BSOL8oyekPPaJ655mXf2OdCZtt3XapiFpjKTZku6X9HlJAyRdA7xKNButc865LjQ0db8AUxwjKktZ39jHgwbROtxriaYwn0q0mt4o4GAz+1oW0uacc3mtJyWNroyoLGN9HylpdJWbIWZ2Vdh+SNKZwDlm5lOIOOdcDI07W9ivrPeN1yMqy9jW3MbWnVHDei512eVW0mBJQyQNIRqnUZX0frdJOlPSIkntkmqS9pdIulnSy5LmSzo27K+Q9ICkV8J1P+rN851zLhviLsDUncRysW/2gdJGVyGrCpgLJPcVezH8NGDfXjx3IXA6cEOH/V8EMLODJA0H/ibp8HDsGjN7XFIJ8HdJHzYzX73POdcn9WQBpu4MrywFYH3Djpx3u+00N2Y2PlMPNbMlQKq+y1OAx8I5GyTVATVm9jzweNjfLOlFYHSm0uecc72VWIApzrTo3UmUNNY35L6kEWtEeBbNB06RVCRpAjAdGJN8gqRq4GPA33OQPueci6Un8051Z0SieqoPBI2MtahIehQYmeLQ5WZ2byeX3QQcSNRTayXwNElTlkgqAm4Hfmlmr3Xx7AuACwDGjh27W+l3zrne6Mm8U90ZUFrEoNIiNjTs7PW9eitjQcPMjt+Na1qBSxLvJT0NLE06ZTbwLzO7tpv7zA7nUlNTYz1Nh3PO9VZPFmCKY0RVWZ9oCI9VPSXpaEmfC9vDQtVR2oVeUgPC9glAq5ktDu9/QNQ4//VMPNs559KpJwswxdFXBvjFWU/j+8C3gcvCrmLgT715qKTTJK0GjgIekPRQODQceFHSkvDMc8P5o4HLiRrKX5Q0T9IXepMG55zLpHRWT0HfGeAXJwSeBhxK6G5rZmslDerNQ81sDjAnxf4VwP4p9q/mnV1/nXOuT0tnQzhEQWND407a242Cgtx9Hcapnmo2MyMam0Gi+sg551zn0l3SGFlZRmu7sXlbbhdpihM07pJ0A1At6YvAo8CNmU2Wc87lt54swBTHiD4yViPO1OjXhEbpBqKqoyvN7JGMp8w55/JYfVMLleXFsRZgimNE0qjwqaOq0nLP3RGrsi0ECQ8UzjkXU932FqrSMBo8YWRV3xjg123QkNRIaM9IUk80AO/SrgbZOefcnqq+qYXqNAaNoQNLkWB9jgf4xSlpXAusBm4j6sF0NjCRqDfVTcCxmUqcc87lq7pQPZUuxYUFDB1YmvNut3Eawk8xsxvMrNHMGsJo6xPN7E5gcIbT55xzeamhqYXqipK03nNEZWnOq6fiBI3tkj4pqSC8PgkkUu1TdDjnXAp125upKk/vTE0jK8ty3nsqTtA4h2hk9gZgfdj+tKRy4OIMps055/JSe7uFNo10lzRyHzTidLl9jWgq8lT+md7kOOdc/tva3Eq7kdbeUxAFjS3bW9jZ2kZpUXrGf/RUnN5TZcDngfcAZYn9ZnZ+BtPlnHN5q357NBq8qiK9QSOxGNOGhp2MGVKR1nvHFad66v8RrYtxIvAk0Yp5jZlMlHPO5bP6phA00lzSSF72NVfiBI1JZvY9YJuZ3QJ8FDgis8lyzrn8lQga6RynAX1jgF+coNESftZJmkq0psXwzCXJOefyW12GqqdGDApBI4djNeL0B5staTBwBXAfMBD4XkZT5ZxzeeztkkZ6e09VVxRTUlTAhsbcjQrvMmhIKgAazGwL8BSwb1ZS5ZxzeayuKZq+PN1tGpIYWZnbZV+7rJ4ys3bgW+l+qKQzJS2S1C6pJml/iaSbJb0sab6kY1Nce5+khelOk3POpUt9UwslRQWUFcdaUbtHRlSW9vmG8EclfVPSGElDEq9ePnchcDpR6SXZFwHM7CDgBOCnobQDgKTTga29fLZzzmVUfZjhNl3ToifL9QC/OG0aZ4WfX0naZ/SiqsrMlgCpPtApwGPhnA2S6oAa4HlJA4FvABcAd+3us51zLtPSPcNtshGVZfx9yQbMLCNBqTtxRoRPyEZCgvnAKZJuB8YA08PP54H/AH4KbO/uJpIuIAoujB07NmOJdc65VNK9lkaykZVlNLW00bCjNWPP6Eq31VOSKiRdIWl2eD9Z0skxrntU0sIUr1O7uOwmomnYa4mmZH8aaJM0DZhoZnPiZMrMZptZjZnVDBs2LM4lzjmXNvVNLVSnubttQq4H+MWpnroZmAu8N7xfA/wZuL+ri8zs+J4mxsxagUsS7yU9DSwFjgFqJK0IaR4u6QkzO7anz3DOuUyrb2rhgL0HZeTeI5PWCt9vRGae0ZU4DeETzezHhEF+ZradaDGmtAulmgFh+wSg1cwWm9l1ZraPmY0HjgaWesBwzvVVmZjhNmHXqPAcdbuNU9JoDtOgG4CkiUCvRpZIOg34FTAMeEDSPDM7kWik+UOS2olKNOf25jnOOZdtLW3tbN2ZufaGEYlJC3M0wC9O0LgKeBAYI+lW4H3AZ3vz0NA28a72CTNbAezfzbUrgKm9eb5zzmVKQ2I0eIbaNMqKC6kqL+67JQ0ze1jSXOBIomqpr5nZpoynzDnn8lBdhma4TZbLAX5x1tP4K3AbcJ+Zbct8kpxzLn/tmhY9QyUNyO0AvzgN4dcA7wcWS7pb0hlhYSbnnHMd7FqAKYMljZGVZTmbHr3boGFmT5rZRUQjwG8APkm0XrhzzrkOMrWWRrIRlWVsbNxJW7tl7BmdiTWbVug99QngQuBw4JZMJso55/JV3fbMzHCbbERVGe0Gm7ZmvwdVnDaNu4AZRD2ofg08GWa/dc4510F9UyuQ4aAx6O1R4YkuuNkSp6Txe6IBfhea2ePAeyX9JsPpcs65vFTX1MzA0iKKCtM/LXpCLgf4xely+5CkQyXNImrPeB34S8ZT5pxzeai+KXOTFSYkShfrczDAr9OgIWk/YFZ4bQLuBGRmH8xS2pxzLu/UZ3CG24ShA0spLBDr+1hJ4xXgH8DJZrYMQNIlXZzvnHN7vEzOcJtQWCCGDSzNSbfbrirdTgfWAY9LulHSTDI0UaFzzvUXdVmonoLcjQrvNGiY2T1mdjZwAPA48HWiKcmvk/ShbCXQOefySTZKGpC7UeFxBvdtM7PbzOxjwGjgJeDbGU+Zc87lGTOjfnsLlVkpaZSxviH7DeE96hNmZlvCqngzM5Ug55zLVzta2mlua8/YWhrJRlaVUd/Uwo6Wtow/K1nmOhI759wepj4LM9wmDB+Um2VfPWg451ya1DVFU4hko00jVwP8chI0JJ0paZGkdkk1SftLJN0s6WVJ8yUd2+HYbElLJb0i6RO5SLtzznUmGzPcJiTWCs92t9s4K/dlwkKiLr03dNj/RQAzO0jScOBvkg4Pc11dDmwws/0kFQBDsppi55zrRjYWYEoYnlj2NcuN4TkJGma2BEB617CPKcBj4ZwNkuqAGuB54Hyi7r+EIOKrBzrn+pRstmlUlhVRXlyY9ZJGX2vTmA+cIqlI0gRgOtHa5NXh+H9IelHSnyWN6Owmki6QVCupduPGjdlIt3PO7aqeykabhqScDPDLWNCQ9KikhSlep3Zx2U3AaqAWuBZ4GmgjKhGNBp42s8OAZ4hWFEwpdAuuMbOaYcOGpS1PzjnXlfqmFgoLxMDS7FTi5GKAX8ZyZmbH78Y1rcCu+a0kPQ0sBTYD23l7dt0/A59PQzKdcy5t6pqaqSovTlX1nhEThg7gbwvfpL3dKCjIzjP7VPWUpApJA8L2CUCrmS02MwP+ChwbTp0JLM5NKp1zLrX6ptastGckzJgwhPqmFl55szFrz8xVl9vTJK0GjgIekPRQODQceFHSEqKpSs5NuuzbwFWSFoT9l2Yzzc4515267c1ZDRpH7LsXAM+9vjlrz8xV78BsNkwAABUISURBVKk5wJwU+1cA+3dyzUrgA5lNmXPO7b6GphaqKzI/hUjCqOpyRg8u5/nX3+Jz75uQlWf2qeop55zLZ3VZmuE22YwJQ3j+9beIavEzz4OGc86lSTaWeu3oyAl7sXlbM8s2bM3K8zxoOOdcGrS3W7SWRpaDxhH7RpNjPPv6W1l5ngcN55xLg8adrZiRlbU0ko0dUsHIyjKe96DhnHP54+3R4NlrCIdoZPiMCUN47rXNWWnX8KDhnHNpkM15pzo6Yt8hbGjcyYrN2zP+LA8azjmXBtlcS6OjIyaE8RqvZX68hgcN55xLg1yWNCYOG8DQgSVZadfwoOGcc2lQl2jTyEHQ2NWu4UHDOefyQ6Kkke3eUwlHTNiLNXVNrHors+0aHjSccy4N6ptaKCsuoKy4MCfPT4zXyHRpw4OGc86lQf327I8GT7bf8EFUVxTzfIYnL/Sg4ZxzQUtbO7c99wZbd7b2+NrEWhq5UlAgDh+f+XYNDxrOORdc/8RyvjvnZf7y4uoeXxtNIZLdgX0dHTFhCCs3b+fN+syt5udBwznngCXrGvjlY/8CoHbFlh5fX7e9JWeN4AlHZmF9DQ8azrk9XktbO/9293yqyos5etJQ5q7sedBoyMG06B0duHclg0qLMlpFlauV+86UtEhSu6SapP0lkm6W9LKk+ZKOTTo2K+xfIOlBSUNzkXbnXP9z/RPLWbimgR98fCozDxzOmrom1tY19egedTmYFr2jwgJRM35wRkeG56qksRA4HXiqw/4vApjZQcAJwE8lFUgqAn4BfNDMDgYWABdnMb3OuX4qUS31sUP24aSpe1MzLuq6WtuD0kZzazvbm9tyMrCvoyP23YvlG7exsXFnRu6fk6BhZkvM7NUUh6YAj4VzNgB1QA2g8BogSUAlsDZLyXXO9VMtbe18889RtdTVp7wHgAP3HkRFSSFzV8Sv4tk1hUiOq6cgagwHMjalSF9r05gPnCKpSNIEYDowxsxagC8DLxMFiynA7zu7iaQLJNVKqt24cWM20u2cy0PXP7GcRWujaqkhA6KeT0WFBRw6tpoXetAYnst5pzqaOqqKipLCjI3XyFjQkPSopIUpXqd2cdlNwGqgFrgWeBpok1RMFDQOBfYhqp66rLObmNlsM6sxs5phw4alLU/Ouf6jY7VUsunjhvDKmw2xx2vUhxlu+0LQKC4sYPq4wRlrDC/KyF0BMzt+N65pBS5JvJf0NLAUmBaOLw/77wK+k56UOuf2NKmqpZLVjBtMu8FLb2zh/ZO7/8MzUdLI9gJMnTliwhCueXgpW7Y1M3hAetPUp6qnJFVIGhC2TwBazWwxsAaYIinxr3cCsCRHyXTO5bmfPbL0XdVSyQ4dW02B4o/XSMxw2xdKGgBn1ozh0W98ICNdgDNW0uiKpNOAXwHDgAckzTOzE4HhwEOS2okCxbkAZrZW0tXAU5JagJXAZ3ORdudcfntk8Xque2I5s2aMeVe1VMKgsmIOGFlJ7cp4VTy7Shp9JGiMqCxjRGVZRu6dk6BhZnOAOSn2rwD27+Sa64HrM5sy51x/9sbm7XzjrnlMHVXJ9z/27mqpZDXjB3P33NW0trVTVNh1pUyipJHrEeHZ0Keqp5xz+c/MaNjRwopN23jxjS38fcl6Vm7elutksaOljS/fOhcB150zvdspzKePG8z25jZeebOx23vXN7UwqKyIwgKlKbV9V05KGs65/ufKexfy4MI32bK9mZY2e8exASWFPPyNYxhVXd7tfdrbjZfX1HPw6CqiYVnpcdV9i1i0toHff6aGMUMquj3/8PHReIcXVrzF1FFVXZ5b3wdGg2eLBw3nXK89s3wzf3xmJcfsN4wD965krwElDB5Qwl4DSigsEBf+aS6Xz3mZmz97eLeB4PqnlvPjB1/lJ2cczJk1Y9KSvj/XruKOF1Zx0bETmXngiFjX7FNdzj5VZdSu3MLn3jehy3Pr+8C8U9niQcM51ytmxs8fXcrwQaXccG7qap9/O3F/rv7rYua8tIbTDxvd6b1eemMLP3t4KQC3PvdGWoLG4rUNXHHPQo7ady++ccJ+Pbp2+vghPP/6Zsysy2BXtz23a2lkk7dpOOd65Znlm3n+9bf48rETO20nOO+o8Rw2tpp/v39xp3MiNexo4at3vMSIyjK+OnMy81bVsXhtQ6/S1rCjhYtunUtVeTG/nHVotw3aHR0+fjDrG3ayekvXkxf2hbU0ssWDhnNutyVKGSMqS5k1Y2yn5xUWiB+fcTDbd7Zx1V8XpbzP9+5ZyNq6Hfxy1jQ+997xlBQVcMcLb+x22lZv2c65v3uOVVua+M05hzFsUGmP7zF93GCAbqdKr2/K/Voa2eJBwzm32/65bBMvrNjCVz44qdveSJOGD+KrMyfxwIJ1PLTozXcc+8uLa7h33lq+NnMy08cNYfCAEj4ydSRzXlzD9uaeL7369yXr+egv/8lrG7fx23MO29Wo3VMHjKxkYGlRl+M1zGyPatPwoOGc2y1mxs8fWcreVWWcdXi8tocvHTORA/eu5Ip7FlIfxja8vmkb37t3ITMmDOErH5y069xPHTGOxp2t3L9gXew0tba186O/vcLnb6ll9OBy7v/q0Zz4npE9y1iSwgJx6NjqLkeGb29uo6XNvE3DOee68tS/NvHiG3V85YOTKC3qupSRUFxYwE/OOJi3tjXzw/9ZQnNrO1+9/SWKCwu49qxp7xjncPj4wUwcNoDbnotXRbW+YQefuvE5rn9yObNmjOW/v/xexu01YLfylqxm3BBeXd+4a9R3R31tNHimedBwLs/saGnjpw+/mtMBc2bGzx5Zyqjqcj7Zwx5OU0dV8cX378udtav4wh9reXlNPf/1iYPZp8MYDknMmjE2VoP408s38ZFf/IOX19Tz87MO4f+eflC31WVx1YwfjIXJC1Ppa/NOZZoHDefyzP/9nyX86rFlXHTrizS3tuckDU+8upH5q+q4+LhJlBT1/Gvk68dPZsLQATy1dCPnHDGWk6amrkL6xGGjKSkq4PbnOy9tLFpbz+f/UEt1RTH3Xfw+Tju08y69u2PamGoKC9RpY3hfWoApGzxoOJdHHn91A7c8s5IjJgxh0doGfvbI0qynIdFjavTgcs6Yvntf0GXFhfxq1qF85qhxXPHRKZ2el2gQv+el1A3im7bu5II/zqW6opjbLziSySMG7VZ6ujKgtIgpe1fyQicr+fWltTSywYOGc3li89adfOvuBew/YhC3nD+DWTPGcMNTy3n2tcys0NaZx17ZwILV9Xz1uMkU93DcQ7Kpo6q4+tSplJd0XY20q0F8/jsbxJtb2/nyn+ayaetOZp9bw/BBmZnVFaKut/NW1dHS9u6SXV9bSyPTPGg4lwfMjO/85WXqt7dw7dnTKCsu5HsnT2H8XgP4xp3zOm2kTaf2duOlN7bwk4deZeyQCk47bFTGnwlRg/ik4QO5LamKysy48t6FvLBiCz858xAOGt313FC9VTN+MDta2lO2rXibhnOuz7nzhVU8sng93zppfw7cuxKAipIifn7WNNY37uTKexdm5Lmtbe08vXwT3793Ie/90WOc9tunWbZhK9/9yAG9KmX0RKoG8T8+s5I7XljFVz44kVMO2SfjaagZF43zuPW5lWzZ1vyOY/VNLRQViAHdlJj6C597yrk+7vVN27j6r4t536S9OL/DxHnTxlTztZmT+dkjSznugOGcOi09f/3PX1XHrc+t5JHF69myvYXSogKO2W8Y35q6PzMPGJH1Rt9PHDaK/3rwFW5//g1OmjqSf79/MccfOJxLT0i5/E7ajawq45RD9uGu2tXcO28tp07bh/OOGs/UUVXUhRlu0zkjb1+Ws6Ah6SfAx4BmYDnwOTOrC8cuAz4PtAFfNbOHwv6TgF8AhcDvzOxHuUi7c9nS0tbO1++cR0lRAdeceQgFKdZruOjYiTy5dCNX3LOQ6eMGM3pw99N+p9La1s7Di9fz+3++ztyVWxhYWsTMA4dz0ntGcsz+w6goyd3fmNUVJXz0oL2Z89Ia7pu/lonDBvDzs6al/Dwy5ZezDuWiD07kj8+sZM6La7irdjWHjq2mqbltj+k5BbmtnnoEmGpmBwNLgcsAJE0BzgbeA5wE/FZSoaRC4DfAh4EpwKxwrnP91q8eW8b8VXX88LSD2Lsq9VoURYUF/PyT02hvNy69az5t7ZbyvM7UN7Vw41OvccxPnuCiW19kY+NOvv+xKTxz2XH84uxD+fBBe+c0YCTMmjGWrTtbkeDG82oYVJb9L+oDRlbyw9MO4tnvzuTKk6dQt72FV95sZOiAns9rla9y9ptgZg8nvX0WOCNsnwrcYWY7gdclLQNmhGPLzOw1AEl3hHMXZyJ9X7jlBVZu3p6JWzsX2/KNWzn9sFF89ODUa1knjN2rgqtOeQ//dvcCPnjNE5T2YOzEmromtje3ccSEIXz/Y1OYeeCIPrkC3eHjB/PND+3H+yYNTctI796oKi/m/KMn8Nn3jufZ1zczbKAHjWw7H7gzbI8iCiIJq8M+gFUd9h+R6maSLgAuABg7tvOZN7sydsiA3Rq05Fw6HbnvXnzrpHj19mdMH83mbc0sWF3Xo2fMmDCEWTPGdrs6Xa5J4uLjJuc6Ge9QUCDeO3ForpORVRkNGpIeBVIN9bzczO4N51wOtAK3puu5ZjYbmA1QU1PTs7J6cOXHvObL5RdJXHjMxFwnw/VzGQ0aZnZ8V8clfRY4GZhpZokv9zVA8mQ2o8M+utjvnHMuC3JW/xJ6Qn0LOMXMkhsP7gPOllQqaQIwGXgeeAGYLGmCpBKixvL7sp1u55zbk+WyTePXQCnwSOjf/KyZXWhmiyTdRdTA3Qp8xczaACRdDDxE1OX2JjN79xJgzjnnMkZv1wr1TzU1NVZbW5vrZDjnXF6RNNfMajru9+5BzjnnYvOg4ZxzLjYPGs4552LzoOGccy62ft8QLmkjsLKb04YCm7KQnL7G871n8XzvWXqb73FmNqzjzn4fNOKQVJuql0B/5/nes3i+9yyZyrdXTznnnIvNg4ZzzrnYPGhEZuc6ATni+d6zeL73LBnJt7dpOOeci81LGs4552LzoOGccy62PTpoSDpJ0quSlkn6Tq7T01uSbpK0QdLCpH1DJD0i6V/h5+CwX5J+GfK+QNJhSdd8Jpz/L0mfyUVeekLSGEmPS1osaZGkr4X9/TrvksokPS9pfsj31WH/BEnPhfzdGZYSICw3cGfY/5yk8Un3uizsf1XSibnJUc9IKpT0kqT7w/s9Jd8rJL0saZ6k2rAve7/rZrZHvoimV18O7AuUAPOBKblOVy/z9AHgMGBh0r4fA98J298B/itsfwT4GyDgSOC5sH8I8Fr4OThsD8513rrJ997AYWF7ELAUmNLf8x7SPzBsFwPPhfzcBZwd9l8PfDlsXwRcH7bPBu4M21PC738pMCH8vyjMdf5i5P8bwG3A/eH9npLvFcDQDvuy9ru+J5c0ZgDLzOw1M2sG7gBOzXGaesXMngLe6rD7VOCWsH0L8PGk/X+0yLNAtaS9gROBR8zsLTPbAjwCnJT51O8+M1tnZi+G7UZgCdG68v067yH9W8Pb4vAy4Djg7rC/Y74Tn8fdwExFi9mcCtxhZjvN7HVgGdH/jz5L0mjgo8DvwnuxB+S7C1n7Xd+Tg8YoYFXS+9VhX38zwszWhe03gRFhu7P85/XnEqoeDiX6q7vf5z1U0cwDNhD9x18O1JlZazglOQ+78heO1wN7kYf5Bq4lWvmzPbzfiz0j3xD9YfCwpLmSLgj7sva7nsuV+1yWmZlJ6rd9rCUNBP4b+LqZNUR/TEb6a94tWtVymqRqYA5wQI6TlHGSTgY2mNlcScfmOj05cLSZrZE0nGjl01eSD2b6d31PLmmsAcYkvR8d9vU360NxlPBzQ9jfWf7z8nORVEwUMG41s7+E3XtE3gHMrA54HDiKqAoi8Qdhch525S8crwI2k3/5fh9wiqQVRNXKxwG/oP/nGwAzWxN+biD6Q2EGWfxd35ODxgvA5NDjooSogey+HKcpE+4DEj0jPgPcm7T/vNC74kigPhRvHwI+JGlw6IHxobCvzwr1078HlpjZz5IO9eu8SxoWShhIKgdOIGrPeRw4I5zWMd+Jz+MM4DGLWkXvA84OvYwmAJOB57OTi54zs8vMbLSZjSf6f/uYmZ1DP883gKQBkgYltol+RxeSzd/1XPcEyOWLqGfBUqJ64MtznZ405Od2YB3QQlRH+Xmiutu/A/8CHgWGhHMF/Cbk/WWgJuk+5xM1Ci4DPpfrfMXI99FE9bwLgHnh9ZH+nnfgYOClkO+FwJVh/75EX37LgD8DpWF/WXi/LBzfN+lel4fP41Xgw7nOWw8+g2N5u/dUv893yOP88FqU+N7K5u+6TyPinHMutj25eso551wPedBwzjkXmwcN55xzsXnQcM45F5sHDeecc7F50HAuBkltYVbRxKvLWZElXSjpvDQ8d4Wkob29j3Pp4l1unYtB0lYzG5iD564g6lu/KdvPdi4VL2k41wuhJPDjsL7B85Imhf1XSfpm2P6qorU+Fki6I+wbIumesO9ZSQeH/XtJeljR+hi/IxqclXjWp8Mz5km6IUxWWCjpD5IWhjRckoOPwe1BPGg4F095h+qps5KO1ZvZQcCviWZf7eg7wKFmdjBwYdh3NfBS2Pdd4I9h//eBf5rZe4jmFRoLIOlA4CzgfWY2DWgDzgGmAaPMbGpIw81pzLNz7+Kz3DoXT1P4sk7l9qSfP09xfAFwq6R7gHvCvqOBTwCY2WOhhFFJtJDW6WH/A5K2hPNnAtOBF8LsveVEk9L9FdhX0q+AB4CHdz+LznXPSxrO9Z51sp3wUaL5fw4j+tLfnT/WBNxiZtPCa38zu8qiBXQOAZ4gKsX8bjfu7VxsHjSc672zkn4+k3xAUgEwxsweB75NNC33QOAfRNVLhDUhNplZA/AU8Kmw/8NES3FCNBndGWENhUSbyLjQs6rAzP4buIIoMDmXMV495Vw85WGFvIQHzSzR7XawpAXATmBWh+sKgT9JqiIqLfzSzOokXQXcFK7bztvTWl8N3C5pEfA08AaAmS2WdAXRim0FRDMZfwVoAm4O+wAuS1+WnXs373LrXC94l1i3p/HqKeecc7F5ScM551xsXtJwzjkXmwcN55xzsXnQcM45F5sHDeecc7F50HDOORfb/wchkr5jf9hu6AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}